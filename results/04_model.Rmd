---
title: "Build prediction model"
author: "Fabien Jossaud, Florent Chuffart"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
---




# Biological clocks

Biological clocks are statstical tools allowing to **predict** age according bilogical parameters.

*e.g.*

$$Age \sim telomere size$$ [Ref.]

$$Age \sim composition cellulaire$$ 

$$Age \sim DNAm$$


Note: Predictive model are different than explanatory model.

*e.g.*

15% of 450k probes are correlated to the age,
but only 71 probes are used in Hannum 2013 clock.











Since, we use the clock metaphore, aging characterizes a shift between chronological age and biologiocal (or predicted) age.
But, more than aging, epigenetic clock points out the DNAm plastic part over time.

Then, we use epigenetic clock (predictiv model) to study cofactor effects (altitude,  air pollution...) on DNAm.
Thereby, epigenetic clock becomes a powerfull ligthweight tool to emphasis effects of cofactor on (15% of) DNAm.

*e.g.* 

In Hannum 2013, Aging Methylation Acceleration Rate (AMAR) according do sex shows differential aging.




Lightness of epigenetic clocks allow to treat cases more powerfully than it could be with DMR.

*e.g.*

clock on 27k  vs. DMR on 27k







Hypothèse : etudier la meth au regard de l’age permet de capturer la partie plastique du DNAm











 

```{r echo=FALSE}
knitr::opts_chunk$set(collapse=TRUE, comment = "#>", fig.width=9, fig.height=6, eval=TRUE, echo=TRUE, results="verbatim")
start_time = Sys.time()
source("common.R")
```

```{r params_default, echo=FALSE}
source("params_default.R")
```

```{r building_indexes, echo=FALSE}
df = mreadRDS(paste0("df_preproc_",gse,".rds"))
idx_samples = rownames(df)
markers_start = grep("cg",colnames(df))[1]
idx_clinicals = colnames(df)[1:(markers_start-1)]
idx_cpg = colnames(df)[markers_start:ncol(df)]
# services patterns
if (!exists("mget_df")) {mget_df = memoise::memoise(function(){df})}
if (!exists("mget_full_cpg_matrix")) {
  get_full_cpg_matrix = function(idx_smp){as.matrix(mget_df()[idx_smp,idx_cpg])}
  mget_full_cpg_matrix = memoise::memoise(get_full_cpg_matrix, cache = cachem::cache_mem(max_size = 10*1024 * 1024^2))
}
```

# Parameters 

```{r parameters}
#Define train and test indexes
# nb_train = floor(nrow(df)/2)

set.seed(1)
idx_train = sample(rownames(df), nb_train)
idx_test = setdiff(rownames(df), idx_train)
# alphas for cva.glmnet
if(!exists("alphas")) alphas = c(.1, .2, .3, .5, .8, 1)
# boostrap 
if (!exists("n_boot")) n_boot = 500
``` 



```{r cva.glmnet call, eval=TRUE, echo=TRUE}
if (!exists("mcvaglmnet")) {
  cvaglmnet = function(idx_train, y_key) {
    x = mget_full_cpg_matrix(idx_train)
    y = mget_df()[idx_train, y_key] # service. Design Patterns, Gamma et al. 
    modelcva = glmnetUtils::cva.glmnet(x=x, y=y, type.measure="mse", standardize=TRUE)
    return(modelcva)  
  }
  # Use parallel::makeCluster is not compatible with memoisation.
  # cl.cva = parallel::makeCluster(nb_cores,  type="FORK")
  # modelcva = glmnetUtils::cva.glmnet(x=x, y=y, type.measure="mse", standardize=TRUE, outerParallel=cl.cva)
  # parallel::stopCluster(cl.cva)
  mcvaglmnet = memoise::memoise(cvaglmnet)
} # Memoise for cvaglmnet

modelcva = mcvaglmnet(idx_train=idx_train, y_key=y_key)

cvarecaps = data.frame(
  lambda   = unlist(lapply(modelcva$modlist, "[[", "lambda")), 
  cvm      = unlist(lapply(modelcva$modlist, "[[", "cvm")   ), 
  cvsd     = unlist(lapply(modelcva$modlist, "[[", "cvsd")   ), 
  cvup     = unlist(lapply(modelcva$modlist, "[[", "cvup")  ),
  cvlo     = unlist(lapply(modelcva$modlist, "[[", "cvlo")  ),
  nbprobes = unlist(lapply(modelcva$modlist, "[[", "nzero") ),
  alpha    = rep(modelcva$alpha, sapply(lapply(modelcva$modlist, "[[", "lambda"), length)),
  nfolds   = modelcva$nfolds
)
cvarecaps$rmse = sqrt(cvarecaps$cvm)
cvarecaps$rmseup = sqrt(cvarecaps$cvup)
cvarecaps$rmselo = sqrt(cvarecaps$cvlo)
cvrecaps = cvarecaps  

head(cvrecaps)
dim(cvrecaps)
```





```{r best_model_cvaglmnet_params}
tmp_alphas = sort(unique(cvrecaps$alpha))
tmp_alphas = unlist(sapply(tmp_alphas, function(alpha) { 
  cvrecap = cvrecaps[cvrecaps$alpha==alpha,]
  if (cvrecap[cvrecap$rmse==min(cvrecap$rmse),]$nbprobes<=.66*length(idx_train)) {
    alpha
  } else {
    NULL
  }
}))

if (!is.null(tmp_alphas)) {
  cvrecaps = cvrecaps[cvrecaps$alpha%in%tmp_alphas,] 
} 

best_model_cvaglmnet_params = cvrecaps[cvrecaps$cvm==min(cvrecaps$cvm),][1,]
best_model_cvaglmnet_params
best_model_cvaglmnet_params
```

# Method

## Elastic net regularization

Elastic net regularization is a method consisting in mix Lasso and Ridge regression methods. We have the metaparameter lambda for Ridge and Lasso regression model (regularization parameter) and the meta parameter alpha corresponding in the proportion of Lasso and Ridge (principe of Elastic net regression).

Meta-parameters are fixed using cross validation.

Cross validation is a process consisting in cutting the train set in k folds. We learn our model on k-1 folds and validate it on the last fold, and we make that k times to validate the model on each folds. We can after make the mean mse to take the best parameters.





```{r plot cva.glmnet results, echo=FALSE}
main = paste0("Cross-Validation nb_train=", nb_train)
# Plotting rmse and nbprobes depending on alpha and lambda (with cv results)
layout(matrix(1:2,1),respect = TRUE)
plot(0, 0, col=0, xlab="log10(lambda)", ylab="RMSE", main=main, xlim=log10(range(cvrecaps$lambda)), ylim=c(0, min(cvrecaps$rmse)*2))
tmp_alphas = sort(unique(cvrecaps$alpha))
foo = lapply(tmp_alphas, function(alpha) { 
  cvrecap = cvrecaps[cvrecaps$alpha==alpha,]
  sub_recap = cvrecap[cvrecap$rmse==min(cvrecap$rmse),]
  tmp_col = which(alpha==tmp_alphas)
  lines(log10(cvrecap$lambda), cvrecap$rmse             , col=tmp_col, lty=2)
  points(  log10(sub_recap$lambda), sub_recap$rmse  , col=tmp_col, pch=1)
  if (best_model_cvaglmnet_params$alpha==alpha & best_model_cvaglmnet_params$lambda==sub_recap$lambda) {
    points(  log10(sub_recap$lambda), sub_recap$rmse  , col=tmp_col, pch=16)
    arrows(x0=log10(sub_recap$lambda), y0=sub_recap$rmselo, x1=log10(sub_recap$lambda), y1=sub_recap$rmseup, code=3, angle=90, length = 0.03, col=tmp_col, lwd=2)
  }    
})
plot(0, 0, col=0, xlab="log10(lambda)", ylab="nbprobes", main=main, xlim=log10(range(cvrecaps$lambda)), ylim=c(0, max(nb_train, best_model_cvaglmnet_params$nbprobes*1.5)))
foo = lapply(tmp_alphas, function(alpha) { 
  cvrecap = cvrecaps[cvrecaps$alpha==alpha,]
  sub_recap = cvrecap[cvrecap$rmse==min(cvrecap$rmse),]
  tmp_col = which(alpha==tmp_alphas)
  lines(log10(cvrecap$lambda), cvrecap$nbprobes         , col=tmp_col, lty=2)
  points(  log10(sub_recap$lambda), sub_recap$nbprobes  , col=tmp_col, pch=1)
  if (best_model_cvaglmnet_params$alpha==alpha & best_model_cvaglmnet_params$lambda==sub_recap$lambda) points(  log10(sub_recap$lambda), sub_recap$nbprobes  , col=tmp_col, pch=16)
})
legend(x="topright", legend=tmp_alphas, fill=1:length(tmp_alphas), title="alpha", cex=.5)
```





```{r loading train/test sets}
#Create Train and Test samples
Xtrain = mget_full_cpg_matrix(idx_train)
Ytrain = mget_df()[idx_train,y_key]
Xtest = mget_full_cpg_matrix(idx_test)
Ytest = mget_df()[idx_test,y_key]
``` 

```{r plot prediction for best model, echo=FALSE}
m = modelcva$modlist[[which(modelcva$alpha==best_model_cvaglmnet_params$alpha)]]
predTr = predict(m, Xtrain, type="response", s="lambda.min")
rmseTr = sqrt(mean((Ytrain - predTr)^2))
predTe = predict(m, Xtest, type="response", s="lambda.min")
rmseTe = sqrt(mean((Ytest - predTe)^2))

layout(matrix(1:2,1), respect=TRUE)
plot(Ytrain, predTr, xlab="Chronological Age", ylab="Predicted Age", main=paste0(m$name, " train rmse: ", signif(rmseTr, 3)))
plot(Ytest , predTe, xlab="Chronological Age", ylab="Predicted Age", main=paste0(m$name, " test  rmse: ", signif(rmseTe, 3))) 
```




```{r glmnet::glmnet memoisation, echo=FALSE}
# model_factory_glmnet, it produces custom model object based on list by calling glmnet::glmnet function
if (!exists("mmodel_factory_glmnet")) {
  model_factory_glmnet = function(idx_train, y_key, alpha=alpha, lambda=lambda) {
    x = mget_full_cpg_matrix(idx_train)
    y = mget_df()[idx_train,y_key]
    m = glmnet::glmnet(x=x, y=y, alpha=alpha, lambda=lambda, standardize=TRUE) 
    idx = rownames(m$beta)[m$beta@i+1]
    coeff=data.frame(probes=idx, beta=m$beta[idx,])
    rownames(coeff) = idx
    coeff$mean = apply(x[,rownames(coeff)], 2, mean)
    ret = list(Intercept=m$a0, coeff=coeff)
    ret$name = paste0("cvaglmnet (a=", signif(alpha,3), ", l=", signif(lambda,3), ")")
    # ret$glmmod = m
    return(ret)
  }
  mmodel_factory_glmnet = memoise::memoise(model_factory_glmnet, cache = cachem::cache_mem(max_size = 10*1024 * 1024^2))
}
```


```{r best_model_cvaglmnet}
m = mmodel_factory_glmnet(idx_train=idx_train, y_key=y_key, alpha=best_model_cvaglmnet_params$alpha, lambda=best_model_cvaglmnet_params$lambda) 

# build model
predTr = Xtrain[,rownames(m$coeff)] %*% as.matrix(m$coeff$beta) + m$Intercept
rmseTr = sqrt(mean((Ytrain - predTr)^2))
predTe = Xtest[,rownames(m$coeff)] %*% as.matrix(m$coeff$beta) + m$Intercept
rmseTe = sqrt(mean((Ytest - predTe)^2))

layout(matrix(1:2,1), respect=TRUE)
plot(Ytrain, predTr, xlab="Chronological Age", ylab="Predicted Age", main=paste0(m$name, " train rmse: ", signif(rmseTr, 3)))
plot(Ytest , predTe, xlab="Chronological Age", ylab="Predicted Age", main=paste0(m$name, " test  rmse: ", signif(rmseTe, 3))) 


best_model_cvaglmnet = m
best_model_cvaglmnet_probes = best_model_cvaglmnet$coeff$probes



build_model_from_probes = function(probes, sub_df, y_key, name) {
  tmp_m = lm(formula(paste0(y_key,"~0+",paste0(probes,collapse="+"))), data=sub_df) #lm model with probes previously find with bootstrap
  idx = probes
  idx = idx[!is.na(tmp_m$coefficients[idx])]
  beta = tmp_m$coefficients[idx]
  coeff = data.frame(probes=idx, beta=beta)
  rownames(coeff) = idx
  coeff$mean = apply(sub_df[,rownames(coeff)], 2, mean)
  head(coeff)
  model = list(coeff=coeff, Intercept=0, name=name)  
  return(model)  
}

sub_df = df[idx_train, c(best_model_cvaglmnet_probes,y_key)]
m = build_model_from_probes(best_model_cvaglmnet_probes, sub_df, y_key, name="best_model_cvaglmnet")

# build model
predTr = Xtrain[,rownames(m$coeff)] %*% as.matrix(m$coeff$beta) + m$Intercept
rmseTr = sqrt(mean((Ytrain - predTr)^2))
predTe = Xtest[,rownames(m$coeff)] %*% as.matrix(m$coeff$beta) + m$Intercept
rmseTe = sqrt(mean((Ytest - predTe)^2))

layout(matrix(1:2,1), respect=TRUE)
plot(Ytrain, predTr, xlab="Chronological Age", ylab="Predicted Age", main=paste0(m$name, " train rmse: ", signif(rmseTr, 3)))
plot(Ytest , predTe, xlab="Chronological Age", ylab="Predicted Age", main=paste0(m$name, " test  rmse: ", signif(rmseTe, 3))) 

```




































```{r bootstrap}
bs_func = function(i, idx_train, best_model_cvaglmnet_params) { #epimedtools to see evolution of running 
  # Bootstrap sample creation
  # print(i)
  set.seed(i)
  idx_bstrain = c(
    sample(idx_train, ceiling(2/3 * length(idx_train)), replace=FALSE),
    sample(idx_train, floor(  1/3 * length(idx_train)), replace=TRUE)
  )
  # Create model with best meta params and bootstrap sample
  # print(best_model_cvaglmnet_params)
  alpha = best_model_cvaglmnet_params$alpha
  lambda = best_model_cvaglmnet_params$lambda
  models_bs = mmodel_factory_glmnet(idx_bstrain, y_key, alpha=alpha, lambda=lambda) 
  # For each bootstrap, capture all probes use in the model 
  probes = rownames(models_bs$coeff)
  return(probes)
}

USE_PARAPPLY = FALSE

if (USE_PARAPPLY) {
  print("bootstrap using parallel::parApply...")
  if (!exists("cl_bs")) {
    cl_bs = parallel::makeCluster(parallel::detectCores(),  type="PSOCK")    
    # parallel::stopCluster(cl_bs)
  }
  bs = parallel::parApply(cl_bs, t(t(1:n_boot)), 1, bs_func, idx_train=idx_train, best_model_cvaglmnet_params=best_model_cvaglmnet_params)
} else {
  print("bootstrap using epimedtools::monitored_apply")
  bs_probes = epimedtools::monitored_apply(mod=1, t(t(1:n_boot)), 1, bs_func, idx_train=idx_train, best_model_cvaglmnet_params=best_model_cvaglmnet_params)   
}

length(bs_probes)
```


```{r robust_probes, echo=FALSE}
layout(matrix(1:2,1),respect = TRUE)
probes = unlist(bs_probes) # probes of all bootstraps
tmp_tab = table(probes) # distribution of all probes
robust_probes = names(tmp_tab)[tmp_tab >= n_boot/2] # probes which appears in more than 50% of models
barplot(table(table(probes)), las=2, 
  xlab="occurence", 
  main=paste0("Probes occurence distribution for ", n_boot, " bootstrap models based on ", best_model_cvaglmnet$name) 
) # barplot of occurence of each probes across bootstraps

barplot(cumsum(rev(table(table(probes)))), las=2, 
  xlab="cumulated occurence", 
  main=paste0("Cumulated probes occurence distribution") 
) # barplot of occurence of each probes across bootstraps
abline(h=length(robust_probes), lty=2, col=2)
text(n_boot/4, length(robust_probes), pos=3, paste0(length(robust_probes), " probes"), col=2)
```

```{r cv_bs, results="hide"}
#  1. folds
n_folds = 3
n_seeds = 3
fold_size = floor(length(idx_train) / n_folds)

folds = lapply(1:n_seeds, function(seed) {
  tmp_folds = list()
  set.seed(seed)
  idx_train_remaining = idx_train
  for (i in 1:n_folds) {
    foo = sample(idx_train_remaining, fold_size)
    tmp_folds[[i]] = list(idx_train=setdiff(idx_train, foo), idx_test=foo)
    idx_train_remaining = setdiff(idx_train, unlist(lapply(tmp_folds, "[[", "idx_test")))
  }
  tmp_folds
})
folds = unlist(folds, recursive=FALSE)

# 2. eval
RMSE = function(data_truth, data_pred) {
    # Root Mean Square Error
    return(sqrt(mean((data_truth - data_pred)^2)))
}

if (!exists("mcall_lm_mod")) {
  call_lm_mod = function(tmp_idx_train, tmp_idx_test, y_key, tmp_probes, occ, fold) {
    m = lm(formula(paste0(y_key,"~0+",paste0(tmp_probes, collapse="+"))), data=sub_df[tmp_idx_train,])
    train_pred = predict(m, sub_df[tmp_idx_train,], type="response")
    train_truth = sub_df[tmp_idx_train, y_key]
    train_err = RMSE(train_truth, train_pred)
    test_pred = predict(m, sub_df[tmp_idx_test,], type="response")
    test_truth = sub_df[tmp_idx_test, y_key]
    test_err = RMSE(test_truth, test_pred)
    # print(paste0("nb_probes:", length(tmp_probes), ", train_err: ", signif(train_err, 3), ", test_err: ", signif(test_err, 3)))
    ret = data.frame(
      occurence=occ, 
      nb_probes=length(tmp_probes), 
      train_err=train_err, 
      test_err=test_err,
      fold=fold
    )
  }
  mcall_lm_mod = memoise::memoise(call_lm_mod)
}


sub_df = df[idx_train, c(robust_probes,y_key)] 
pb_occ_tab = sort(table(unlist(bs_probes))) # probe occurence


iterator = sort(unique(pb_occ_tab[pb_occ_tab>=n_boot/2]))
if (length(iterator) == 1 ) {
  iterator = sort(unique(pb_occ_tab))
  sub_df = df[idx_train, c(names(pb_occ_tab),y_key)] 
}
stats = epimedtools::monitored_apply(mod=1, t(t(iterator)), 1, function(occ) {
  # print(occ)
  tmp_probes = names(pb_occ_tab)[pb_occ_tab>=occ]
  stats = lapply(1:length(folds), function(fold) {
    # print(fold)
    tmp_idx_train = folds[[fold]]$idx_train
    tmp_idx_test = folds[[fold]]$idx_test
    ret = mcall_lm_mod(tmp_idx_train, tmp_idx_test, y_key, tmp_probes, occ, fold)
    return(ret)
  })
  stats = do.call(rbind, stats)
  stats
})
stats = do.call(rbind, stats)
head(stats)
```




## Bootstrap

Bootstrap is a method consisting in sample a new train set based on the original train set. We repete the method a big number of times, more we repete it, more the results are robusts. 
To create the new train set, we sample 2/3 of sample on original train set without replace and 1/3 with replace. That create a new train set used to make our model.
We repete this method n_boot times and, at the end, we select for our final model only the markers shows on more than a certain pourcentage on bootstraps models. That create a final model more robusts than if we just make one model on our original train set, so this method increases robustness of results.

```{r plot_cv_each_bs, echo=FALSE, eval=TRUE}
# # 3. plot
stats$labs = factor(paste0(stats$occurence, "  (", stats$nb_probes, " probes)"))
layout(1,respect = TRUE)
par(mar=c(10, 4.1, 4.1, 2.1))
foo = boxplot(train_err~labs, data=stats, border=1, las=2, ylab="RMSE", main="Cross Validation for occurence min", xlab="")
bar = boxplot( test_err~labs, data=stats, border=2, las=2, ylab="RMSE", main="Cross Validation", add=TRUE, xlab="probes occurence")
legend("bottomright", col=1:2, c("train", "test"), pch=1)
idx = floor(ncol(bar$stats)*.5)
# idx = 2
# for(lty in 3:1) {
#   tmp_lev = mean(bar$stats[3,1:floor(idx/2)])
#   idx = which(foo$stats[3,] - tmp_lev>0)[1]
#   abline(h=tmp_lev, col=2, lty=lty)
#   abline(v=idx, col=1, lty=lty)
# }
# idx = rev(which(bar$stats[3,] < tmp_lev))[1]
abline(v=idx, col=2, lty=1)
best_params = bar$names[idx]
text(idx-1, min(foo$stats[3,]), best_params, col=2, srt=90, pos=3)
occ_optim = as.numeric(strsplit(best_params, " ")[[1]][1])
best_model_bs_probes = names(pb_occ_tab[pb_occ_tab>occ_optim])
par(mar=c(5.1, 4.1, 4.1, 2.1))
```


```{r best_model_bs_probes}
best_model_bs_probes
```

















```{r best_model_bs}
sub_df = df[idx_train,c(probes,y_key)] 
best_model_bs = build_model_from_probes(best_model_bs_probes, sub_df, y_key, name="BMBS")
```





```{r plot models_bs}
#Plot rmse like with cross validation but with bootstrap results
layout(matrix(1:2,1), respect=TRUE)
m = best_model_bs
predTr = Xtrain[,rownames(m$coeff)] %*% as.matrix(m$coeff$beta) + m$Intercept
rmseTr = sqrt(mean((Ytrain - predTr)^2))
predTe = Xtest[,rownames(m$coeff)] %*% as.matrix(m$coeff$beta) + m$Intercept
rmseTe = sqrt(mean((Ytest - predTe)^2))
plot(predTr, Ytrain, xlab="Predicted Age", ylab="Chronological Age", main = paste0(m$name, " RMSE: ", signif(rmseTr, 3)))
plot(predTe, Ytest , xlab="Predicted Age", ylab="Chronological Age", main = paste0(m$name, " RMSE: ", signif(rmseTe, 3)))  
```



# Model Evaluation



```{r amar plotting, fig.width=12, fig.height=9, echo=FALSE}
layout(matrix(1:12,3), respect=TRUE)
litterature_models = readRDS("litterature_models.rds")

hannum_probes = intersect(colnames(df), litterature_models$hannum_model_mc$coeff$probes)
sub_df = df[idx_train, c(hannum_probes,y_key)]
hannum_model = build_model_from_probes(hannum_probes, sub_df, y_key, name="Hannum")

horvath_probes = intersect(colnames(df), litterature_models$horvath_model_mc$coeff$probes)
sub_df = df[idx_train, c(horvath_probes,y_key)]
horvath_model = build_model_from_probes(horvath_probes, sub_df, y_key, name="Horvath")

models = list(best_model_cvaglmnet, best_model_bs, hannum_model, horvath_model)


for (covariate in covariates) {
  df[,covariate] = as.factor(df[,covariate])
  levls = levels(df[,covariate])
  tmp_col = RColorBrewer::brewer.pal(n=max(3,length(levls)), name = "Set1")
  for (m in models) {
  
    # Imputing missing probes (litterature_models)
    tmp_Xtrain = Xtrain[,rownames(m$coeff)[rownames(m$coeff) %in% colnames(Xtrain)]] #Keep only common CpG between coeffs and Xtrain
    tmp_Xtest = Xtest[,rownames(m$coeff)[rownames(m$coeff) %in% colnames(Xtest)]] #Keep only common CpG between coeffs and Xtrain

    idx_missing_probes = rownames(m$coeff)[!(rownames(m$coeff) %in% colnames(Xtrain))]
    if (length(idx_missing_probes) != 0) {
      foo = m$coeff[idx_missing_probes,"mean"]
      names(foo) = idx_missing_probes
      tmp_Xtrain = cbind(tmp_Xtrain,do.call("rbind",replicate(nrow(tmp_Xtrain),foo,simplify=FALSE)))
      tmp_Xtest = cbind(tmp_Xtest,do.call("rbind",replicate(nrow(tmp_Xtest),foo,simplify=FALSE)))
    }
  
    tmp_Xtrain = tmp_Xtrain[,rownames(m$coeff)]
    tmp_Xtest = tmp_Xtest[,rownames(m$coeff)]
  
    predTr = tmp_Xtrain %*% as.matrix(m$coeff$beta) + m$Intercept
    rmseTr = sqrt(mean((Ytrain - predTr)^2))
    predTe = tmp_Xtest %*% as.matrix(m$coeff$beta) + m$Intercept
    rmseTe = sqrt(mean((Ytest - predTe)^2))
    AMAR_Te = predTe/Ytest
    AMAR_Te = cbind.data.frame(AMAR_Te,df[rownames(AMAR_Te),covariate])

    colnames(AMAR_Te) = c("AMAR", covariate)
  
    pval = anova(lm(AMAR_Te[,1]~AMAR_Te[,2], data=AMAR_Te))[1,5]
  
    den = density(AMAR_Te[, "AMAR"], na.rm=TRUE)
    den_bw = den$bw
    # den_bw = .07
    density = lapply(levls, function(lev){
      if (sum(AMAR_Te[,covariate] %in% lev) > 1) {
        den = density(bw=den_bw, AMAR_Te[AMAR_Te[,covariate] %in% lev, "AMAR"])
        return(den)
      } # Patch density
    })



    plot(Ytrain, predTr,
      main=paste0(m$name), 
      sub=paste0("TRAIN (", nrow(m$coeff), " pbs)", " RMSE: ", signif(rmseTr, 3)), 
      xlab="Chronological Age", 
      ylab="Predicted Age"
      )
    abline(a=0, b=1)                                                                    

    plot(Ytest , predTe, 
      main = paste0(m$name), 
      sub=paste0("TEST (", nrow(m$coeff), " pbs) RMSE: ", signif(rmseTe, 3)), 
      xlab="Chronological Age", 
      ylab="Predicted Age" 
    )
    abline(a=0, b=1)


    plot(0,0, xlim = c(0.5, 1.5), #min(unlist(lapply(density, function(d){min(d$x)}))),max(unlist(lapply(density, function(d){max(d$x)})))), 
      ylim = c(0, max(unlist(lapply(density, function(d){max(d$y)})))), 
    main = paste0("AMAR pval=", signif(pval ,3)))
    sub="ANOVA"
		for (j in c(1:length(levls))){
			lines(density[[j]],col = tmp_col[j])
		}
		legend(x="topright", legend=levls, col=tmp_col, lty = 1, title=covariate)           
  }
}
```



# Discussion

For each alpha, we see the occurence of each probes across bootstraps.


Discussion, a **core of probes** are always selected by bootstrap.

- What is the relevance of the clock built with only this core of probes? #biostat
- Which one? What are associated biologiocal functions? #biologist 
- Are these probes located into wild Differebnttion Metrhylation Region (DMR)? #biologist


## Hannum probes

For each alpha, we see the occurence of Hannum probes across bootstraps.

```{r hannum distribution}
layout(1, respect=TRUE)
# layout(matrix(1:2,1),respect = TRUE)
if (!exists("mget_coefHannum")) mget_coefHannum = memoise::memoise(methylclockData::get_coefHannum)
hannum_coeff = mget_coefHannum() # Get Hannum probes
probes = unlist(bs_probes)
tmp_tab = table(probes)
tmp_tab_Hannum = tmp_tab[hannum_coeff$CpGmarker] # Occurence of each Hannum's probes
tmp_tab_Hannum[is.na(tmp_tab_Hannum)] = 0  # If no occurences, set 0 
barplot(table(tmp_tab_Hannum), las=2, main=paste0("Hannum probes in ", sum(tmp_tab_Hannum >= n_boot/2), " probes.")) # Plot occurences of Hannum probes across bootstraps
foo = names(tmp_tab_Hannum)[tmp_tab_Hannum >= n_boot/2]
unique(unlist(foo))
```

## Occurrence of probes along of boostrap process

Follow the number of retained probes along of the bootstraps process

```{r probes_occurrence, eval=FALSE}
layout(matrix(1:2,1),respect = TRUE)
# layout(matrix(1:(length(models)*2),2), respect=TRUE)
x = seq(2,n_boot,2) # Sequence of even bootstraps
tmp_probes = lapply(x, function(nb_boot){ # when the number of bootstrap is even 
  tmp_probes = unlist(bs_probes[1:nb_boot]) 
  tmp_tab = table(tmp_probes)
  tmp_boot_cpg = names(tmp_tab)[tmp_tab >= nb_boot/2] # Check probes appears more than 50% times
  return(tmp_boot_cpg)
})
# barplot(sort(table(unlist(tmp_probes))))
nb_probes = unlist(sapply(tmp_probes, length)) # Check number of probes across boostraps
plot(x, nb_probes, type = "l", main ="") # Plot number of probes across bootstraps
tab_probes = table(nb_probes) 
barplot(tab_probes, las=2) # Check when number of probes stabilised
```

















# Session Information

```{r, results="verbatim"}
end_time = Sys.time()
print(paste0("Execution time for vignette : ", end_time - start_time))
sessionInfo()
```
