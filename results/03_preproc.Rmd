---
title: "Code Hannum 2013"
---
title: "Descriptive Statistics"
author: "Fabien Jossaud, Florent Chuffart"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
---


```{r include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, comment = "#>", fig.width=9, fig.height=6, eval=TRUE, echo=TRUE, results="verbatim")
```


# Call data (Need to be modified to generalize and make it at a variable)

```{r Call data}
if (!exists("mreadRDS")) { mreadRDS = memoise::memoise(readRDS) }
if (!exists("df_GSE40279")) {
  df_GSE40279 = mreadRDS("df_GSE40279.rds")  
}
df = df_GSE40279

idx_samples = rownames(df)


head(df[,1:7])
idx_clinicals = colnames(df)[1:7]


head(df[,(ncol(df)-10):ncol(df)])
idx_cpg = colnames(df)[8:ncol(df)][1:10000]
tail (idx_cpg)

# Check data with 100 first variables of 20 first individuals 
df[1:20,1:10]
dim(df)
```




# Pretreatment

## Missing values

```{r Missing Values}
if (sum(is.na(df[,idx_cpg]))>0) {
  # Looking how much got more than 5% missing values
  # apply_func = epimedtools::monitored_apply
  if (! exists("apply_func")) {apply_func = apply}
  prop_na_row =  apply_func(is.na(df[,idx_cpg]), 1, sum) / ncol(df)
  idx_cpg     = names(prop_na_col)[prop_na_col<.05]
  prop_na_col =  apply_func(is.na(df[,idx_cpg]), 2, sum) / nrow(df)
  idx_samples = names(prop_na_row)[prop_na_row<.05]
  df = df[idx_samples, c(idx_clinicals, idx_cpg)]

  ## KNN - We use the function impute.knn of the package impute to replace remaining missing values with KNN method. 
  dknn <- df
  dknnf <- impute::impute.knn(df, k=10, maxp=5000, rng.seed=1)
  df <- dknnf$data
}
```


# Outliers 

## ACP 

We first make an ACP to find outliers.

```{r ACP}
pdaj = 1
idx_samples
it=1
while(sum(padj < 0.2) != 0) {
  print(paste0("*******", it))
  it = it+1
  mat = as.matrix(df[idx_samples, idx_cpg])
  pca = prcomp(mat, scale=FALSE)
  v = pca$sdev * pca$sdev
  p = v / sum(v) * 100

  layout(matrix(1:6,2), respect=TRUE)
  # layout(matrix(1:2,1), respect=TRUE)
  barplot(p)

  for (i in 1:5) {
    j = i+1
    plot(pca$x[,i], pca$x[,j], xlab=paste0("PC", i, "(", signif(p[i], 3), "%)"), ylab=paste0("PC", j, "(", signif(p[j], 3), "%)"), pch=16)  
    # scale_factor = min(abs(c(min(c(pca$x[,i], pca$x[,j])), max(c(pca$x[,i], pca$x[,j])))))
    # scale_factor = min(abs(c(max(min(pca$x[,i]), min(pca$x[,j])), min(max(pca$x[,i]), max(pca$x[,j])))))
    # arrows(0,0,pca$rotation[,i]*scale_factor, pca$rotation[,j]*scale_factor, col="grey")
    # text(pca$rotation[,i]*scale_factor, pca$rotation[,j]*scale_factor, rownames(pca$rotation))
  }

  head(pca$x[,1:2])

  mean = mean(pca$x[,1])
  sd = sd(pca$x[,1])
  pval = pnorm(abs(pca$x[,1]), mean, sd, lower.tail=FALSE)
  padj = p.adjust(pval, method="BH")
  sum(padj <= 0.2)
  range(padj)  
  idx_samples = names(padj)[padj > 0.2]
}
```


## Z-score 

We calculate z-score based on our ACP. 

```{r zscore}



```

## Z-score transformation in FDR

We converted all z-scores in FDR with Gaussian cumulative distribution and the Benjamini-Hochberg procedure. 

```{r FDR Transformation}



```

## Outliers deleting 

We delete all samples with a FDR < 0.2 . 

```{r Delete Outliers}



```

## Remake procedures 

We remake ACP and procedures with new cohort (without outliers) to find new outliers. We stop this procedures when we find no outliers. 

```{r Remake Outliers}



``` 

# Model 

## Find Variables for model 

```{r Prepare Model}

Xtrain <- d[,-(1:7)]
Ytrain <- d[,"age__y_"]

``` 

## Finding Best Model
 
### Test Classic regression

We test the package glmnet with a classic regression (lambda = 0)

```{r Classic Regression}

modelCR <- glmnet(Xtrain,Ytrain,family="binomial",standardize=TRUE,lambda=0)

```

### Cross Validation

We're trying to find best parameters for the ElasticNet regression (alpha>0 and lambda>0) with the function cv.glmnet 
 
```{r Cross Validation}



```

### Model with best parameters 

Now we have all parameters to construct our model

```{r ModelCV}



```

### Bootstrapping

But we have to make bootstrap to make our model stronger. We take CV parameters calculate above for each bootstrap cohort.

```{r Bootstrapping}



```

### Markers choice for final model 

We choose only markers find in +50% of our bootstrap models

```{Choosing Markers}



``` 

### Covariables 






# Session Information

```{r, results="verbatim"}
sessionInfo()
```

